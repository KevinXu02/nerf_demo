{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import viser, time  # pip install viser\n",
    "import numpy as np\n",
    "from data import data_loader\n",
    "from utils import sample_along_rays\n",
    "from utils import get_intrinsic_matrix\n",
    "from rays import RaysData\n",
    "from utils import transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images_train, c2ws_train, _, _, _, focal = data_loader()\n",
    "K = get_intrinsic_matrix(focal, images_train.shape[1], images_train.shape[2])\n",
    "dataset = RaysData(images_train, K, c2ws_train,focal=focal)\n",
    "rays_o, rays_d, pixels = dataset.sample_rays(100)\n",
    "points = sample_along_rays(rays_o, rays_d, perturb=True)\n",
    "H, W = images_train.shape[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def volrend(sigmas, rgbs, step_size):\n",
    "    # sigmas: Nxn_samplesx1 tensor\n",
    "    # rgbs: Nxn_samplesx3 tensor\n",
    "    # step_size: Nxn_samplesx1 tensor\n",
    "    # return: N x 3 tensor \n",
    "    alpha = 1.0 - torch.exp(-sigmas * step_size)\n",
    "    alpha=alpha.squeeze()\n",
    "    T_i = torch.cat([torch.ones_like(alpha[:, :1]), 1.0 - alpha], dim=-1)[:, :-1]\n",
    "    T_i = torch.cumprod(T_i, dim=-1)\n",
    "    weights = alpha * T_i\n",
    "    colors = torch.sum(weights.unsqueeze(-1) * rgbs, dim=-2)\n",
    "    return colors\n",
    "\n",
    "def pos_encoding(L, x):\n",
    "        # apply a serious of sinusoidal functions to the input cooridnates, to expand its dimensionality\n",
    "        # pe(x)={x,sin(πx),cos(πx),sin(2^1πx),cos(2^1πx),...,sin(2^(L-1)πx),cos(2^(l-1)πx)}\n",
    "        # x: [N, 3]\n",
    "        # L: int\n",
    "        # return: [N, 3 * L + 3]\n",
    "        x = x.unsqueeze(-1)\n",
    "        l = torch.arange(L, dtype=torch.float32, device=x.device)\n",
    "        l = 2**l\n",
    "        x = x * l * torch.pi\n",
    "        x = torch.cat([x.sin(), x.cos()], dim=-1)\n",
    "        return x.flatten(-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_encoding(10, torch.rand(1, 3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "sigmas = torch.rand((10, 64, 1))\n",
    "rgbs = torch.rand((10, 64, 3))\n",
    "step_size = (6.0 - 2.0) / 64\n",
    "step_size = torch.ones((10, 64, 1)) * step_size\n",
    "rendered_colors = volrend(sigmas, rgbs, step_size)\n",
    "\n",
    "correct = torch.tensor([\n",
    "    [0.5006, 0.3728, 0.4728],\n",
    "    [0.4322, 0.3559, 0.4134],\n",
    "    [0.4027, 0.4394, 0.4610],\n",
    "    [0.4514, 0.3829, 0.4196],\n",
    "    [0.4002, 0.4599, 0.4103],\n",
    "    [0.4471, 0.4044, 0.4069],\n",
    "    [0.4285, 0.4072, 0.3777],\n",
    "    [0.4152, 0.4190, 0.4361],\n",
    "    [0.4051, 0.3651, 0.3969],\n",
    "    [0.3253, 0.3587, 0.4215]\n",
    "  ])\n",
    "torch.allclose(rendered_colors, correct, rtol=1e-4, atol=1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
