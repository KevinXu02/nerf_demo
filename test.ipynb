{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import viser, time  # pip install viser\n",
    "import numpy as np\n",
    "from data import data_loader\n",
    "from utils import sample_along_rays,sample_along_rays_np\n",
    "from utils import get_intrinsic_matrix\n",
    "from rays import RaysData\n",
    "from utils import transform\n",
    "from utils import viser_visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step_size.shape (64,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 64 into shape (100,64,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Kevin\\Documents\\Berkeley\\nerf\\nerf_demo\\test.ipynb 单元格 2\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Kevin/Documents/Berkeley/nerf/nerf_demo/test.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m rays_o, rays_d, pixels \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39msample_rays(\u001b[39m100\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Kevin/Documents/Berkeley/nerf/nerf_demo/test.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pixels\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mtile(pixels[:,\u001b[39mNone\u001b[39;00m,:],(\u001b[39m1\u001b[39m,\u001b[39m64\u001b[39m,\u001b[39m1\u001b[39m))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Kevin/Documents/Berkeley/nerf/nerf_demo/test.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m point \u001b[39m=\u001b[39m sample_along_rays_np(rays_o, rays_d, perturb\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Kevin/Documents/Berkeley/nerf/nerf_demo/test.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m H, W \u001b[39m=\u001b[39m images_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:\u001b[39m3\u001b[39m]\n",
      "File \u001b[1;32md:\\Kevin\\Documents\\Berkeley\\nerf\\nerf_demo\\utils.py:93\u001b[0m, in \u001b[0;36msample_along_rays_np\u001b[1;34m(rays_o, rays_d, near, far, n_samples, perturb)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m         points_all \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack((points_all, points))\n\u001b[1;32m---> 93\u001b[0m \u001b[39mreturn\u001b[39;00m points_all\u001b[39m.\u001b[39mreshape(N, n_samples, \u001b[39m3\u001b[39m), step_size\u001b[39m.\u001b[39;49mreshape(N, n_samples, \u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 64 into shape (100,64,1)"
     ]
    }
   ],
   "source": [
    "\n",
    "images_train, c2ws_train, _, _, _, focal = data_loader()\n",
    "K = get_intrinsic_matrix(focal, images_train.shape[1], images_train.shape[2])\n",
    "dataset = RaysData(images_train, K, c2ws_train,focal=focal)\n",
    "rays_o, rays_d, pixels = dataset.sample_rays(100)\n",
    "pixels=np.tile(pixels[:,None,:],(1,64,1))\n",
    "point = sample_along_rays_np(rays_o, rays_d, perturb=True)\n",
    "H, W = images_train.shape[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────── <span style=\"font-weight: bold\">viser</span> ───────────────╮\n",
       "│             ╷                       │\n",
       "│   HTTP      │ http://0.0.0.0:8084   │\n",
       "│   Websocket │ ws://0.0.0.0:8084     │\n",
       "│             ╵                       │\n",
       "╰─────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────── \u001b[1mviser\u001b[0m ───────────────╮\n",
       "│             ╷                       │\n",
       "│   HTTP      │ http://0.0.0.0:8084   │\n",
       "│   Websocket │ ws://0.0.0.0:8084     │\n",
       "│             ╵                       │\n",
       "╰─────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Share URL requested!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Share URL requested!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Kevin\\Documents\\Berkeley\\nerf\\nerf_demo\\test.ipynb 单元格 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Kevin/Documents/Berkeley/nerf/nerf_demo/test.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# visualize rays_o\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Kevin/Documents/Berkeley/nerf/nerf_demo/test.ipynb#W5sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     server\u001b[39m.\u001b[39madd_point_cloud(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Kevin/Documents/Berkeley/nerf/nerf_demo/test.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/rays_o/\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Kevin/Documents/Berkeley/nerf/nerf_demo/test.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         colors\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mzeros_like(o)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Kevin/Documents/Berkeley/nerf/nerf_demo/test.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         points\u001b[39m=\u001b[39mo\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Kevin/Documents/Berkeley/nerf/nerf_demo/test.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         point_size\u001b[39m=\u001b[39m\u001b[39m0.02\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Kevin/Documents/Berkeley/nerf/nerf_demo/test.ipynb#W5sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Kevin/Documents/Berkeley/nerf/nerf_demo/test.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m server\u001b[39m.\u001b[39madd_point_cloud(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Kevin/Documents/Berkeley/nerf/nerf_demo/test.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/samples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Kevin/Documents/Berkeley/nerf/nerf_demo/test.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     colors\u001b[39m=\u001b[39mpixels\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m),\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Kevin/Documents/Berkeley/nerf/nerf_demo/test.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     points\u001b[39m=\u001b[39mpoint\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Kevin/Documents/Berkeley/nerf/nerf_demo/test.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     point_size\u001b[39m=\u001b[39m\u001b[39m0.02\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Kevin/Documents/Berkeley/nerf/nerf_demo/test.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Kevin/Documents/Berkeley/nerf/nerf_demo/test.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m1000\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'reshape'"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Share URL <span style=\"font-weight: bold\">(</span>expires in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> hours<span style=\"font-weight: bold\">)</span>: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://validate-absolute.share.viser.studio</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Share URL \u001b[1m(\u001b[0mexpires in \u001b[1;36m24\u001b[0m hours\u001b[1m)\u001b[0m: \u001b[4;94mhttps://validate-absolute.share.viser.studio\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Share URL <span style=\"font-weight: bold\">(</span>expires in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> hours<span style=\"font-weight: bold\">)</span>: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://lip-k-means.share.viser.studio</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Share URL \u001b[1m(\u001b[0mexpires in \u001b[1;36m24\u001b[0m hours\u001b[1m)\u001b[0m: \u001b[4;94mhttps://lip-k-means.share.viser.studio\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "server = viser.ViserServer(share=True)\n",
    "for i, (image, c2w) in enumerate(zip(images_train, c2ws_train)):\n",
    "    server.add_camera_frustum(\n",
    "        f\"/cameras/{i}\",\n",
    "        fov=2 * np.arctan2(H / 2, K[0, 0]),\n",
    "        aspect=W / H,\n",
    "        scale=0.15,\n",
    "        wxyz=viser.transforms.SO3.from_matrix(c2w[:3, :3]).wxyz,\n",
    "        position=c2w[:3, 3],\n",
    "        image=image,\n",
    "    )\n",
    "for i, (o, d) in enumerate(zip(rays_o, rays_d)):\n",
    "    server.add_spline_catmull_rom(\n",
    "        f\"/rays/{i}\",\n",
    "        positions=np.stack((o, o + d * 6.0)),\n",
    "    )\n",
    "    # visualize rays_o\n",
    "    server.add_point_cloud(\n",
    "        f\"/rays_o/{i}\",\n",
    "        colors=np.zeros_like(o).reshape(-1, 3),\n",
    "        points=o.reshape(-1, 3),\n",
    "        point_size=0.02,\n",
    "    )\n",
    "server.add_point_cloud(\n",
    "    f\"/samples\",\n",
    "    colors=pixels.reshape(-1, 3),\n",
    "    points=point.reshape(-1, 3),\n",
    "    point_size=0.02,\n",
    ")\n",
    "time.sleep(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from utils import volrend,pos_encoding\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 60])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_encoding(torch.rand(5, 3),10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625],\n",
      "        [0.0625]])\n",
      "tensor([[0.5006, 0.3728, 0.4728],\n",
      "        [0.4322, 0.3559, 0.4134],\n",
      "        [0.4027, 0.4394, 0.4610],\n",
      "        [0.4514, 0.3829, 0.4196],\n",
      "        [0.4002, 0.4599, 0.4103],\n",
      "        [0.4471, 0.4044, 0.4069],\n",
      "        [0.4285, 0.4072, 0.3777],\n",
      "        [0.4152, 0.4190, 0.4361],\n",
      "        [0.4051, 0.3651, 0.3969],\n",
      "        [0.3253, 0.3587, 0.4215]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from utils import volrend\n",
    "\n",
    "torch.manual_seed(42)\n",
    "sigmas = torch.rand((10, 64, 1))\n",
    "rgbs = torch.rand((10, 64, 3))\n",
    "step_size = (6.0 - 2.0) / 64\n",
    "step_size = torch.ones((64, 1)) * step_size\n",
    "rendered_colors = volrend(sigmas, rgbs, step_size)\n",
    "\n",
    "correct = torch.tensor([\n",
    "    [0.5006, 0.3728, 0.4728],\n",
    "    [0.4322, 0.3559, 0.4134],\n",
    "    [0.4027, 0.4394, 0.4610],\n",
    "    [0.4514, 0.3829, 0.4196],\n",
    "    [0.4002, 0.4599, 0.4103],\n",
    "    [0.4471, 0.4044, 0.4069],\n",
    "    [0.4285, 0.4072, 0.3777],\n",
    "    [0.4152, 0.4190, 0.4361],\n",
    "    [0.4051, 0.3651, 0.3969],\n",
    "    [0.3253, 0.3587, 0.4215]\n",
    "  ])\n",
    "print(step_size)\n",
    "print(rendered_colors)\n",
    "torch.allclose(rendered_colors, correct, rtol=1e-4, atol=1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
